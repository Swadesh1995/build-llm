{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82ab03d",
   "metadata": {},
   "source": [
    "# Example Without Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be0bdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1326, -0.6088],\n",
       "         [-0.1689, -0.7603],\n",
       "         [-0.1853, -0.8077],\n",
       "         [-0.1602, -0.7431],\n",
       "         [-0.2002, -0.6679],\n",
       "         [-0.1580, -0.6887]],\n",
       "\n",
       "        [[-0.1326, -0.6088],\n",
       "         [-0.1689, -0.7603],\n",
       "         [-0.1853, -0.8077],\n",
       "         [-0.1602, -0.7431],\n",
       "         [-0.2002, -0.6679],\n",
       "         [-0.1580, -0.6887]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch,torch.nn as nn\n",
    "class CausalAttentionWithoutBuffers(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out=d_out\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.mask=torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in=x.shape\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "        attn_scores=queries@keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens,\n",
    "                                                  :num_tokens],-torch.inf)\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec\n",
    "inputs=torch.tensor([[.43,.15,.89],\n",
    "                     [.55,.87,.66],\n",
    "                     [.57,.85,.64],\n",
    "                     [.22,.58,.33],\n",
    "                     [.77,.25,.1],\n",
    "                     [.05,.8,.55]])\n",
    "batch=torch.stack((inputs,inputs),dim=0)\n",
    "context_length=batch.shape[1]\n",
    "d_in=inputs.shape[1]\n",
    "d_out=2\n",
    "ca_without_buffer=CausalAttentionWithoutBuffers(d_in,d_out,context_length,0)\n",
    "with torch.no_grad():\n",
    "    context_vecs=ca_without_buffer(batch)\n",
    "context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a298cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine has GPU: True\n"
     ]
    }
   ],
   "source": [
    "has_mps=torch.backends.mps.is_available()\n",
    "print(f'Machine has GPU: {has_mps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae069fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('mps')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867f32e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query.device: mps:0\n",
      "mask.device: cpu\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "batch=batch.to(device)\n",
    "ca_without_buffer=ca_without_buffer.to(device)\n",
    "print(f'W_query.device: {ca_without_buffer.W_query.weight.device}\\nmask.device: {ca_without_buffer.mask.device}\\n{type(ca_without_buffer.mask)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53b1070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask.device: mps:0\n"
     ]
    }
   ],
   "source": [
    "ca_without_buffer.mask=ca_without_buffer.mask.to(device)\n",
    "print(f'mask.device: {ca_without_buffer.mask.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04d0319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1326, -0.6088],\n",
       "         [-0.1689, -0.7603],\n",
       "         [-0.1853, -0.8077],\n",
       "         [-0.1602, -0.7431],\n",
       "         [-0.2002, -0.6679],\n",
       "         [-0.1580, -0.6887]],\n",
       "\n",
       "        [[-0.1326, -0.6088],\n",
       "         [-0.1689, -0.7603],\n",
       "         [-0.1853, -0.8077],\n",
       "         [-0.1602, -0.7431],\n",
       "         [-0.2002, -0.6679],\n",
       "         [-0.1580, -0.6887]]], device='mps:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    context_vecs=ca_without_buffer(batch)\n",
    "context_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f60a35",
   "metadata": {},
   "source": [
    "# Example With Buffers\n",
    "## Buffers, state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc94e932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W_query.weight',\n",
       "              tensor([[-0.0850, -0.0829, -0.4284],\n",
       "                      [ 0.3573, -0.4932, -0.4831]], device='mps:0')),\n",
       "             ('W_key.weight',\n",
       "              tensor([[ 0.4202,  0.2805, -0.5325],\n",
       "                      [-0.2468, -0.3244, -0.5748]], device='mps:0')),\n",
       "             ('W_value.weight',\n",
       "              tensor([[-0.4955,  0.0073,  0.0892],\n",
       "                      [-0.2776, -0.5334, -0.4600]], device='mps:0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CausalAttentionWithBuffer(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out=d_out\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.register_buffer('mask',torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in=x.shape\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "        attn_scores=queries@keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens,\n",
    "                                                  :num_tokens],-torch.inf)\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec\n",
    "ca_with_buffer=CausalAttentionWithBuffer(d_in,d_out,context_length,0)\n",
    "ca_with_buffer.to(device)\n",
    "ca_without_buffer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db771e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mask',\n",
       "              tensor([[0., 1., 1., 1., 1., 1.],\n",
       "                      [0., 0., 1., 1., 1., 1.],\n",
       "                      [0., 0., 0., 1., 1., 1.],\n",
       "                      [0., 0., 0., 0., 1., 1.],\n",
       "                      [0., 0., 0., 0., 0., 1.],\n",
       "                      [0., 0., 0., 0., 0., 0.]], device='mps:0')),\n",
       "             ('W_query.weight',\n",
       "              tensor([[-0.1735, -0.2387, -0.0884],\n",
       "                      [ 0.1110, -0.1784, -0.2616]], device='mps:0')),\n",
       "             ('W_key.weight',\n",
       "              tensor([[-0.0903,  0.4589,  0.3723],\n",
       "                      [ 0.5692, -0.0475, -0.1776]], device='mps:0')),\n",
       "             ('W_value.weight',\n",
       "              tensor([[-0.0305, -0.2526,  0.1203],\n",
       "                      [ 0.0751,  0.4521,  0.3481]], device='mps:0'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_with_buffer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02263b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 2., 2., 2., 2.],\n",
       "        [0., 0., 2., 2., 2., 2.],\n",
       "        [0., 0., 0., 2., 2., 2.],\n",
       "        [0., 0., 0., 0., 2., 2.],\n",
       "        [0., 0., 0., 0., 0., 2.],\n",
       "        [0., 0., 0., 0., 0., 0.]], device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_with_buffer.mask[ca_with_buffer.mask==1]=2\n",
    "ca_with_buffer.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e05abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 2., 2., 2., 2.],\n",
       "        [0., 0., 2., 2., 2., 2.],\n",
       "        [0., 0., 0., 2., 2., 2.],\n",
       "        [0., 0., 0., 0., 2., 2.],\n",
       "        [0., 0., 0., 0., 0., 2.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(ca_with_buffer.state_dict(),'model.pth')\n",
    "new_ca_with_buffer=CausalAttentionWithBuffer(d_in,d_out,context_length,0)\n",
    "new_ca_with_buffer.load_state_dict(torch.load('model.pth'))\n",
    "new_ca_with_buffer.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc7cc09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_without_buffer.mask[ca_without_buffer.mask==1]=2\n",
    "torch.save(ca_without_buffer.state_dict(),'model.pth')\n",
    "new_ca_without_buffer=CausalAttentionWithoutBuffers(d_in,d_out,context_length,0)\n",
    "new_ca_without_buffer.load_state_dict(torch.load('model.pth'))\n",
    "new_ca_without_buffer.mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
