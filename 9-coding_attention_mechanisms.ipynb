{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f35ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import torch,torch.nn as nn\n",
    "print(f\"Torch version: {version('torch')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e92c05",
   "metadata": {},
   "source": [
    "# Attending To Different Parts Of Input With Self-Attention\n",
    "## Simple Self-Attention Mechanism Without Trainable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8de043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=torch.tensor([[.43,.15,.89],\n",
    "                     [.55,.87,.66],\n",
    "                     [.57,.85,.64],\n",
    "                     [.22,.58,.33],\n",
    "                     [.77,.25,.1],\n",
    "                     [.05,.8,.55]])\n",
    "query=inputs[1]\n",
    "attn_scores_2=torch.empty(inputs.shape[0])\n",
    "for i,x_i in enumerate(inputs):\n",
    "    attn_scores_2[i]=torch.dot(x_i,query)\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a0fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9544)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=0\n",
    "for idx,element in enumerate(inputs[0]):\n",
    "    res+=inputs[0][idx]*query[idx]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d7e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp=attn_scores_2/attn_scores_2.sum()\n",
    "print(f'Attention weights: {attn_weights_2_tmp}\\nSum: {attn_weights_2_tmp.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad87d609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
    "attn_weights_2_naive=softmax_naive(attn_scores_2)\n",
    "print(f'Attention weights: {attn_weights_2_naive}\\nSum: {attn_weights_2_naive.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098ed106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2=torch.softmax(attn_scores_2,dim=0)\n",
    "query=inputs[1]\n",
    "context_vec_2=torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2+=attn_weights_2[i]*x_i\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908459e8",
   "metadata": {},
   "source": [
    "## Computing Attention Weights For All Input Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82ed268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores=torch.empty(6,6)\n",
    "attn_scores=inputs@inputs.T\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25587a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights=torch.softmax(attn_scores,dim=-1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a4ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 sum: 1.0\n",
      "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_2_sum=sum([.1385,.2379,.2333,.124,.1082,.1581])\n",
    "print(f'Row 2 sum: {row_2_sum}\\nAll row sums: {attn_weights.sum(dim=-1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd34913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n",
      "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs=attn_weights@inputs\n",
    "print(f'{all_context_vecs}\\nPrevious 2nd context vector: {context_vec_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81b055",
   "metadata": {},
   "source": [
    "# Implementing Self-Attention With Trainable Weights\n",
    "## Computing Attention Weights Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51313e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1910, 0.9843])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2=inputs[1]\n",
    "d_in=inputs.shape[1]\n",
    "d_out=2\n",
    "W_query=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "query_2=x_2@W_query\n",
    "key_2=x_2@W_key \n",
    "value_2=x_2@W_value\n",
    "query_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b8b8327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys=inputs@W_key \n",
    "values=inputs@W_value\n",
    "print(f'keys.shape: {keys.shape}\\nvalues.shape: {values.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf31ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5368)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_2=keys[1]\n",
    "attn_score_22=query_2.dot(keys_2)\n",
    "attn_score_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40896c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9034, 1.5368, 1.5338, 0.8304, 1.0483, 0.9155])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_2=query_2@keys.T\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc667018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1390, 0.2176, 0.2171, 0.1320, 0.1540, 0.1402])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k=keys.shape[1]\n",
    "attn_weights_2=torch.softmax(attn_scores_2/d_k**.5,dim=-1)\n",
    "attn_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "729161d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0064, 1.0248])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2=attn_weights_2@values\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9d3f69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0648, 0.9735],\n",
       "        [1.0831, 0.9858],\n",
       "        [1.0840, 0.9864],\n",
       "        [1.0507, 0.9568],\n",
       "        [1.0812, 0.9812],\n",
       "        [1.0449, 0.9533]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.W_query=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=nn.Parameter(torch.rand(d_in,d_out))\n",
    "    def forward(self,x):\n",
    "        keys=x@self.W_key\n",
    "        queries=x@self.W_query\n",
    "        values=x@self.W_value\n",
    "        attn_scores=queries@keys.T\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec\n",
    "sa_v1=SelfAttention_v1(d_in,d_out)\n",
    "sa_v1(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f455d427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0962, 0.1514],\n",
       "        [0.0965, 0.1543],\n",
       "        [0.0965, 0.1542],\n",
       "        [0.0962, 0.1532],\n",
       "        [0.0961, 0.1510],\n",
       "        [0.0964, 0.1545]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    def forward(self,x):\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "        attn_scores=queries@keys.T\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec\n",
    "sa_v2=SelfAttention_v2(d_in,d_out)\n",
    "sa_v2(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924bc5c",
   "metadata": {},
   "source": [
    "# Hiding Future Words With Causal Attention\n",
    "## Applying Causal Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2bc80db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1658, 0.1717, 0.1716, 0.1624, 0.1645, 0.1640],\n",
       "        [0.1740, 0.1693, 0.1693, 0.1612, 0.1637, 0.1626],\n",
       "        [0.1736, 0.1695, 0.1694, 0.1612, 0.1637, 0.1626],\n",
       "        [0.1724, 0.1673, 0.1672, 0.1637, 0.1650, 0.1644],\n",
       "        [0.1654, 0.1706, 0.1705, 0.1636, 0.1651, 0.1648],\n",
       "        [0.1760, 0.1664, 0.1663, 0.1630, 0.1646, 0.1636]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries=sa_v2.W_query(inputs)\n",
    "keys=sa_v2.W_key(inputs) \n",
    "attn_scores=queries@keys.T\n",
    "attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20bd4ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length=attn_scores.shape[0]\n",
    "mask_simple=torch.tril(torch.ones(context_length,context_length))\n",
    "mask_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf3eb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1658, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1740, 0.1693, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1736, 0.1695, 0.1694, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1724, 0.1673, 0.1672, 0.1637, 0.0000, 0.0000],\n",
       "        [0.1654, 0.1706, 0.1705, 0.1636, 0.1651, 0.0000],\n",
       "        [0.1760, 0.1664, 0.1663, 0.1630, 0.1646, 0.1636]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_simple=attn_weights*mask_simple\n",
    "masked_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "485bcd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5068, 0.4932, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3388, 0.3307, 0.3305, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2571, 0.2494, 0.2494, 0.2442, 0.0000, 0.0000],\n",
       "        [0.1980, 0.2043, 0.2042, 0.1959, 0.1977, 0.0000],\n",
       "        [0.1760, 0.1664, 0.1663, 0.1630, 0.1646, 0.1636]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums=masked_simple.sum(dim=-1,\n",
    "                           keepdim=True)\n",
    "masked_simple_norm=masked_simple/row_sums\n",
    "masked_simple_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88f89758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1170,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.1624, 0.1241,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.1606, 0.1262, 0.1255,   -inf,   -inf,   -inf],\n",
       "        [0.0885, 0.0457, 0.0454, 0.0156,   -inf,   -inf],\n",
       "        [0.0834, 0.1275, 0.1269, 0.0684, 0.0812,   -inf],\n",
       "        [0.1116, 0.0316, 0.0313, 0.0030, 0.0166, 0.0082]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
    "masked=attn_scores.masked_fill(mask.bool(),-torch.inf)\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a01f3ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5068, 0.4932, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3388, 0.3307, 0.3305, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2571, 0.2494, 0.2494, 0.2442, 0.0000, 0.0000],\n",
       "        [0.1980, 0.2043, 0.2042, 0.1959, 0.1977, 0.0000],\n",
       "        [0.1760, 0.1664, 0.1663, 0.1630, 0.1646, 0.1636]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights=torch.softmax(masked/keys.shape[-1]**.5,dim=-1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4683638",
   "metadata": {},
   "source": [
    "## Masking Additional Attention Weights With Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73fac8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 2., 2., 0., 0.],\n",
       "        [2., 2., 0., 0., 2., 2.],\n",
       "        [2., 0., 2., 0., 2., 0.],\n",
       "        [0., 2., 0., 0., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 2.],\n",
       "        [0., 0., 2., 0., 2., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout=torch.nn.Dropout(.5)\n",
    "example=torch.ones(6,6)\n",
    "dropout(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f7393a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0135, 0.9865, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.6610, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4988, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3960, 0.0000, 0.4084, 0.3918, 0.3954, 0.0000],\n",
       "        [0.3521, 0.3327, 0.3326, 0.0000, 0.3292, 0.3273]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ea8ee",
   "metadata": {},
   "source": [
    "## Implementing Compact Causal Self-Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cf6acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=torch.stack((inputs,inputs),dim=0)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af5ca064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3282,  0.0936],\n",
      "         [-0.4517,  0.1618],\n",
      "         [-0.4805,  0.1857],\n",
      "         [-0.4516,  0.1627],\n",
      "         [-0.3364,  0.1961],\n",
      "         [-0.3885,  0.1684]],\n",
      "\n",
      "        [[-0.3282,  0.0936],\n",
      "         [-0.4517,  0.1618],\n",
      "         [-0.4805,  0.1857],\n",
      "         [-0.4516,  0.1627],\n",
      "         [-0.3364,  0.1961],\n",
      "         [-0.3885,  0.1684]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out=d_out\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.register_buffer('mask',torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in=x.shape\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "        attn_scores=queries@keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens,\n",
    "                                                  :num_tokens],-torch.inf)\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec\n",
    "context_length=batch.shape[1]\n",
    "ca=CausalAttention(d_in,d_out,context_length,0)\n",
    "context_vecs=ca(batch)\n",
    "print(f'{context_vecs}\\ncontext_vecs.shape: {context_vecs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793eff21",
   "metadata": {},
   "source": [
    "# Extending Single To MHA\n",
    "## Stacking Multiple Single-Head Attention Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "636b2ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0101,  0.1371,  0.3000,  0.0332],\n",
      "         [-0.1396, -0.0091,  0.1687,  0.1241],\n",
      "         [-0.1905, -0.0499,  0.1168,  0.1547],\n",
      "         [-0.1790, -0.0758,  0.0790,  0.1624],\n",
      "         [-0.2179, -0.0168,  0.0341,  0.1156],\n",
      "         [-0.1955, -0.0632,  0.0372,  0.1399]],\n",
      "\n",
      "        [[ 0.0101,  0.1371,  0.3000,  0.0332],\n",
      "         [-0.1396, -0.0091,  0.1687,  0.1241],\n",
      "         [-0.1905, -0.0499,  0.1168,  0.1547],\n",
      "         [-0.1790, -0.0758,  0.0790,  0.1624],\n",
      "         [-0.2179, -0.0168,  0.0341,  0.1156],\n",
      "         [-0.1955, -0.0632,  0.0372,  0.1399]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([CausalAttention(d_in,d_out,context_length,dropout,qkv_bias) for _ in range(num_heads)])\n",
    "    def forward(self,x):\n",
    "        return torch.cat([head(x) for head in self.heads],dim=-1)\n",
    "context_length=batch.shape[1]\n",
    "d_in,d_out=3,2\n",
    "mha=MultiHeadAttentionWrapper(d_in,d_out,context_length,0,num_heads=2)\n",
    "context_vecs=mha(batch)\n",
    "print(f'{context_vecs}\\ncontext_vecs.shape: {context_vecs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9b017",
   "metadata": {},
   "source": [
    "## Implementing MHA With Weight Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9996c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1650,  0.3430],\n",
      "         [-0.0802,  0.4443],\n",
      "         [-0.1536,  0.4775],\n",
      "         [-0.1298,  0.4528],\n",
      "         [-0.0799,  0.4977],\n",
      "         [-0.1025,  0.4644]],\n",
      "\n",
      "        [[ 0.1650,  0.3430],\n",
      "         [-0.0802,  0.4443],\n",
      "         [-0.1536,  0.4775],\n",
      "         [-0.1298,  0.4528],\n",
      "         [-0.0799,  0.4977],\n",
      "         [-0.1025,  0.4644]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out%num_heads==0),'d_out must be divisible by num_heads.'\n",
    "        self.d_out=d_out\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=d_out//num_heads\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.out_proj=nn.Linear(d_out,d_out)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.register_buffer('mask',torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in=x.shape\n",
    "        keys=self.W_key(x)\n",
    "        queries=self.W_query(x)\n",
    "        values=self.W_value(x)\n",
    "        keys=keys.view(b,num_tokens,self.num_heads,self.head_dim) \n",
    "        values=values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        queries=queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        keys=keys.transpose(1,2)\n",
    "        queries=queries.transpose(1,2)\n",
    "        values=values.transpose(1,2)\n",
    "        attn_scores=queries@keys.transpose(2,3)\n",
    "        mask_bool=self.mask.bool()[:num_tokens,\n",
    "                                   :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "        context_vec=(attn_weights@values).transpose(1,2) \n",
    "        context_vec=context_vec.contiguous().view(b,num_tokens,self.d_out)\n",
    "        context_vec=self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "batch_size,context_length,d_in=batch.shape\n",
    "d_out=2\n",
    "mha=MultiHeadAttention(d_in,d_out,context_length,0,num_heads=2)\n",
    "context_vecs=mha(batch)\n",
    "print(f'{context_vecs}\\ncontext_vecs.shape: {context_vecs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cabe513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.3208, 1.1631, 1.2879],\n",
       "          [1.1631, 2.2150, 1.8424],\n",
       "          [1.2879, 1.8424, 2.0402]],\n",
       "\n",
       "         [[0.4391, 0.7003, 0.5903],\n",
       "          [0.7003, 1.3737, 1.0620],\n",
       "          [0.5903, 1.0620, 0.9912]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([[[[.2745,.6584,.2775,.8573],\n",
    "                  [.8993,.039,.9268,.7388],\n",
    "                  [.7179,.7058,.9156,.434]],\n",
    "                 [[.0772,.3565,.1479,.5331],\n",
    "                  [.4066,.2318,.4545,.9737],\n",
    "                  [.4606,.5159,.422,.5786]]]])\n",
    "a@a.transpose(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eb949ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st head:\n",
      "tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n"
     ]
    }
   ],
   "source": [
    "first_head=a[0,0,:,:]\n",
    "first_res=first_head@first_head.T\n",
    "print(f'1st head:\\n{first_res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e97e3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd head:\n",
      "tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "second_head=a[0,1,:,:]\n",
    "second_res=second_head@second_head.T\n",
    "print(f'2nd head:\\n{second_res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68001d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0962, 0.1514],\n",
       "        [0.0965, 0.1543],\n",
       "        [0.0965, 0.1542],\n",
       "        [0.0962, 0.1532],\n",
       "        [0.0961, 0.1510],\n",
       "        [0.0964, 0.1545]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.d_out=d_out\n",
    "        self.W_query=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key=nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value=nn.Parameter(torch.rand(d_in,d_out))\n",
    "    def forward(self,x):\n",
    "        keys=x@self.W_key\n",
    "        queries=x@self.W_query\n",
    "        values=x@self.W_value\n",
    "        attn_scores=queries@keys.T\n",
    "        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**.5,dim=-1)\n",
    "        context_vec=attn_weights@values\n",
    "        return context_vec\n",
    "sa_v1=SelfAttention_v1(d_in,d_out)\n",
    "sa_v1.W_query=torch.nn.Parameter(sa_v2.W_query.weight.T)\n",
    "sa_v1.W_key=torch.nn.Parameter(sa_v2.W_key.weight.T)\n",
    "sa_v1.W_value=torch.nn.Parameter(sa_v2.W_value.weight.T)\n",
    "sa_v1(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
